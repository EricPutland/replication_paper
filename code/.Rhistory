h1 = hclust(d1)
cuttree
cutree()
cutree(h1)
cutree(h1,k=2)
table(cutree(h1,k=2))
edata=as.data.frame(exprs(mp))
edata = log2(edata +1)
set.seed(1235)
k = kmeans(t(edata),centers=2)
clust_k = k$cluster
d1 = dist(t(edata))
h1 = hclust(d1)
clust_h = cutree(h1,k=2)
table(clust_h,pdata$study)
table(clust_h)
con =url("http://bowtie-bio.sourceforge.net/recount/ExpressionSets/montpick_eset.RData")
load(file=con)
close(con)
mp = montpick.eset
pdata=pData(mp)
edata=as.data.frame(exprs(mp))
fdata = fData(mp)
edata = log2(edata +1)
set.seed(1235)
k = kmeans(t(edata),centers=2)
clust_k = k$cluster
clust_k
table(clust_k)
table(clust_k,pdata$study)
d1 = dist(t(edata))
h1 = hclust(d1)
clust_h = cutree(h1,k=2)
table(clust_h)
table(clust_h,pdata$study)
table(clust_k,pdata$study)
mymyplclust(h1,lab.col=as.numeric(pdata$study))
myplclust(h1,lab.col=as.numeric(pdata$study))
dat = read.table("~/Downloads/table_for_heatmap.tsv")
dat = read.table("~/Downloads/table_for_heatmap.tsv",sep="\t",header=F,row.names=1)
dim(dat)
dat[1,]
rownames(dat)
library(gplot2)
library(gplots)
dat
heatmap.2(dat,col=colramp,Rowv=NA,Colv=NA,
dendrogram="none", scale="row",trace="none")
library(RSkittleBrewer)
trop = RSkittleBrewer("tropical")
palette(trop)
par(pch=19)
colramp = colorRampPalette(c(3,"white",2))(9)
heatmap.2(ematrix,col=colramp,Rowv=NA,Colv=NA,
dendrogram="none", scale="row",trace="none")
heatmap.2(dat,col=colramp,Rowv=NA,Colv=NA,
dendrogram="none", scale="row",trace="none")
heatmap.2(as.matrix(dat),col=colramp,Rowv=NA,Colv=NA,
dendrogram="none", scale="row",trace="none")
png(file="~/Desktop/heatmap-test.png",height=(2*480),width=(2*480))
heatmap.2(as.matrix(dat),col=colramp,Rowv=NA,Colv=NA,
dendrogram="none", scale="row",trace="none")
dev.off()
heatmap.2(ematrix,col=colramp,Rowv=NA,Colv=NA,
dendrogram="none", scale="row",trace="none",
lmat = rbind(4:3,2:1),lwid = c(1.5,4),lhei = c(1,4))
heatmap.2(dat,col=colramp,Rowv=NA,Colv=NA,
dendrogram="none", scale="row",trace="none",
lmat = rbind(4:3,2:1),lwid = c(1.5,4),lhei = c(1,4))
png(file="~/Desktop/heatmap-test.png",height=(2*480),width=(2*480))
heatmap.2(dat,col=colramp,Rowv=NA,Colv=NA,
dendrogram="none", scale="row",trace="none",
lmat = rbind(4:3,2:1),lwid = c(1.5,4),lhei = c(1,4))
heatmap.2(as.matrix(dat),col=colramp,Rowv=NA,Colv=NA,
dendrogram="none", scale="row",trace="none",
lmat = rbind(4:3,2:1),lwid = c(1.5,4),lhei = c(1,4))
dev.off()
heatmap.2(as.matrix(dat),col=colramp,Rowv=NA,Colv=NA,
dendrogram="none", scale="row",trace="none",
lmat = rbind(4:3,2:1),lwid = c(1,4),lhei = c(0.75,4))
png(file="~/Desktop/heatmap-test.png",height=(2*480),width=(2*480))
heatmap.2(as.matrix(dat),col=colramp,Rowv=NA,Colv=NA,
dendrogram="none", scale="row",trace="none",
lmat = rbind(4:3,2:1),lwid = c(1,4),lhei = c(0.75,4))
dev.off()
heatmap.2(ematrix,col=colramp,Colv=NA,
dendrogram="none", scale="row",trace="none",
lmat = rbind(4:3,2:1),lwid = c(1.5,4),lhei = c(1,4))
heatmap.2(as.matrix(dat),col=colramp,Colv=NA,
dendrogram="none", scale="row",trace="none",
lmat = rbind(4:3,2:1),lwid = c(1,4),lhei = c(0.75,4))
?heatmap.2
heatmap.2(as.matrix(dat),col=colramp,Colv=NA,
dendrogram="row", scale="row",trace="none",
lmat = rbind(4:3,2:1),lwid = c(1,4),lhei = c(0.75,4))
heatmap.2(as.matrix(dat),col=colramp,
dendrogram="row", scale="row",trace="none",
lmat = rbind(4:3,2:1),lwid = c(1,4),lhei = c(0.75,4))
?heatmap.2
heatmap.2(as.matrix(dat),col=colramp,
dendrogram="row", scale="row",trace="none",
lmat = rbind(4:3,2:1),lwid = c(1,4),lhei = c(0.75,4))
png(file="~/Desktop/heatmap-test.png",height=(2*480),width=(2*480))
heatmap.2(as.matrix(dat),col=colramp,
dendrogram="row", scale="row",trace="none",
lmat = rbind(4:3,2:1),lwid = c(1,4),lhei = c(0.75,4))
dev.off()
k = kmeans(dat,k=5)
?kmeans
k = kmeans(dat,centers=5)
heatmap.2(as.matrix(dat)[k$cluster,],col=colramp,
dendrogram="none", scale="row",trace="none",
lmat = rbind(4:3,2:1),lwid = c(1,4),lhei = c(0.75,4))
png(file="~/Desktop/heatmap-test.png",height=(2*480),width=(2*480))
heatmap.2(as.matrix(dat)[k$cluster,],col=colramp,
dendrogram="none", scale="row",trace="none",
lmat = rbind(4:3,2:1),lwid = c(1,4),lhei = c(0.75,4))
dev.off()
png(file="~/Desktop/heatmap-test.png",height=(2*480),width=(2*480))
heatmap.2(as.matrix(dat),col=colramp,
dendrogram="row", scale="row",trace="none",
lmat = rbind(4:3,2:1),lwid = c(1,4),lhei = c(0.75,4))
dev.off()
## An example of a processing pipeline
<img class=center src=../../assets/img/03_ObtainingData/hiseq.jpeg height=450/>
[http://www.illumina.com.cn/support/sequencing/sequencing_instruments/hiseq_1000.asp](http://www.illumina.com.cn/support/sequencing/sequencing_instruments/hiseq_1000.asp)
---
## An example of a processing pipeline
<img class=center src=../../assets/img/03_ObtainingData/processing.png height=400 />
[http://www.cbcb.umd.edu/~hcorrada/CMSC858B/lectures/lect22_seqIntro/seqIntro.pdf](http://www.cbcb.umd.edu/~hcorrada/CMSC858B/lectures/lect22_seqIntro/seqIntro.pdf)
library(dplyr)
my_db <- src_sqlite("my_db.sqlite3", create = T)
library(nycflights13)
flights_sqlite <- copy_to(my_db, flights, temporary = FALSE, indexes = list(
c("year", "month", "day"), "carrier", "tailnum"))
install.packages("nycflights13")
flights_sqlite <- copy_to(my_db, flights, temporary = FALSE, indexes = list(
c("year", "month", "day"), "carrier", "tailnum"))
library(nycflights13)
flights_sqlite <- copy_to(my_db, flights, temporary = FALSE, indexes = list(
c("year", "month", "day"), "carrier", "tailnum"))
flights_sqlite <- tbl(nycflights13_sqlite(), "flights")
flights_sqlite
class(flights_sqlite)
install.packages("RMySql")
install.packages("RMySQL")
library(RMySQL)
install.packages("RMySQL")
library(RMySQL)
affyData <- dbReadTable(hg19, "affyU133Plus2")
hg19 <- dbConnect(MySQL(),user="genome", db="hg19",
host="genome-mysql.cse.ucsc.edu")
allTables <- dbListTables(hg19)
length(allTables)
allTables[1:5]
affyData <- dbReadTable(hg19, "affyU133Plus2")
warnings()
affydata[1,]
affyData[1,]
rm((flights_sqlite)
rm((flights_sqlite))
rm(flights_sqlite)
my_db
rm(my_db)
library(readr)
read_cvs
read_csv()
read_csv
library(gplots)
library(devtools)
library(Biobase)
library(RSkittleBrewer)
library(org.Hs.eg.db)
library(AnnotationDbi)
library(RSkittleBrewer)
# Make the colors pretty
trop = RSkittleBrewer("tropical")
palette(trop)
par(pch=19)
library(gplots)
library(googlesheets)
my_url = "https://docs.google.com/spreadsheets/d/1El48mUK2FVPt_i6WlsvukFoYF1uCU00MqqLeY7W46LE/pubhtml"
my_gs = gs_url(my_url)
dat = gs_read(my_gs)
### plot
library(RSkittleBrewer)
trop = RSkittleBrewer("tropical")
colramp = colorRampPalette(c(trop[3],"white",trop[2]))(9)
palette(trop)
dat = as.matrix(dat)
dat[is.na(dat)]= 0
par(mar=c(5,5,5,5))
heatmap.2(as.matrix(dat),col=colramp,Rowv=NA,Colv=NA,
dendrogram="none", scale="none",
trace="none",margins=c(10,2))
setwd("~/Downloads/")
students = read.csv("711_Data_Analysis_I.csv")
dim(students)
students[1,]
length(students)
students
students = read.csv("711_Data_Analysis_I.csv",header=F)
students
class(students)
dim(students)
dim(students)[1]
rmultinom
?rmultinom
graders = c("Jeff","Elizabeth","John","Yates")
sample(graders,size=17,replace=T)
set.seed(123)
graders = c("Jeff","Elizabeth","John","Yates")
dat = read.csv("711_Data_Analysis_I.csv",header=F)
dat$grader = sample(graders,size=17,replace=T)
dat
table(dat$grader)
set.seed(333)
graders = c("Jeff","Elizabeth","John","Yates")
dat = read.csv("711_Data_Analysis_I.csv",header=F)
dat$grader = sample(graders,size=17,replace=T)
dat$grader
table(dat$grader)
set.seed(333)
graders = c(rep("Jeff",5),rep("Elizabeth",4),rep("John",4),rep("Yates",4))
dat = read.csv("711_Data_Analysis_I.csv",header=F)
dat$grader = sample(graders)
dat
table(dat$graders)
table(dat$grader)
args(write.csv)
?write.csv
dat
setwd("~/Dropbox/Jeff/2015/replication_paper/code")
library(knitr)
purl("replication_analysis.Rmd")
## ----load_packages,message=FALSE-----------------------------------------
library(dplyr)
library(RCurl)
library(grid)
library(ggplot2)
library(downloader)
library(gridExtra)
library(extrafont)
## ----download_data,message=FALSE,warning=FALSE---------------------------
download("https://osf.io/fgjvw/?action=download",destfile="../data/rpp_data.csv")
download("https://osf.io/bhcsf/?action=download",destfile="../data/rpp_data_codebook.csv")
date_downloaded = date()
date()
## ----read_data,message=FALSE,warning=FALSE-------------------------------
## Here we follow
dat = read.csv("../data/rpp_data.csv",stringsAsFactors=F)
fdat = dplyr::filter(dat, !is.na(T_pval_USE..O.), !is.na(T_pval_USE..R.))
## 99 expected
nrow(fdat)
idOK <- complete.cases(fdat$T_r..O.,fdat$T_r..R.)
## 97 expected
sum(idOK)
## ----reproduce_plot,message=FALSE,warning=FALSE--------------------------
## Got this from https://github.com/FredHasselman/toolboxR/blob/master/C-3PR.R was having trouble with the
## sourcing
source("utils.R")
mytheme <- gg.theme("clean")
## Line 149 needed to make numeric
fdat$Power..R. <- as.numeric(fdat$Power..R.)
fdat$oriSig = "Not Significant"
fdat$oriSig[fdat$T_pval_USE..O.<=.06] = "Significant"
fdat$oriSig = factor(fdat$oriSig)
fdat$repSig = "Not Significant"
fdat$repSig[fdat$T_pval_USE..R.<=.05] = "Significant"
fdat$repSig = factor(fdat$repSig)
blankPlot <- plotHolder()
xDense <- ggplot(fdat, aes(x=T_r..O., fill=oriSig)) +
geom_density(aes(y= ..count..),trim=F,alpha=.5) +
xlab("") + ylab("") + xlim(0,1) +
gg.theme("noax") +
theme(legend.position = "none",plot.margin = unit(c(0,0,0,4), "lines"))
yDense <- ggplot(fdat, aes(x=T_r..R., fill=repSig)) +
geom_density(aes(y= ..count..),trim=F,alpha=.5) +
xlab("") + ylab("") + xlim(-.5,1) +
coord_flip() +
gg.theme("noax") +
theme(legend.position = "none", plot.margin = unit(c(0,0,3,0), "lines"))
scatterP<-
ggplot(fdat,aes(x=T_r..O.,y=T_r..R.)) +
geom_hline(aes(yintercept=0),linetype=2) +
geom_abline(intercept=0,slope=1,color="Grey60")+
geom_point(aes(size=Power..R.,fill=repSig),color="Grey30",shape=21,alpha=.8) +
geom_rug(aes(color=oriSig),size=1,sides="b",alpha=.6) +
geom_rug(aes(color=repSig),size=1,sides="l",alpha=.6) +
scale_x_continuous(name="Original Effect Size",limits=c(0,1),breaks=c(0,.25,.5,.75,1)) +
scale_y_continuous(name="Replication Effect Size",limits=c(-.5,1),breaks=c(-.5,-.25,0,.25,.5,.75,1)) +
ggtitle("") + xlab("") + ylab("") +
scale_size_continuous(name="Replication Power",range=c(2,9)) +
scale_color_discrete(name="p-value") +
scale_fill_discrete(name="p-value") +
gg.theme("clean") +
theme(legend.position=c(.9,.6), plot.margin = unit(c(-2,-1.5,2,2), "lines"))
grid.arrange(xDense, blankPlot, scatterP, yDense, ncol=2, nrow=2, widths=c(4, 1.4), heights=c(1.4, 4))
dim(fdat)
colnames(dat)[1] = "ID"
cor_orig = dat$T_r..O.
cor_rep = dat$T_r..R.
n_orig = dat$T_df2..O. + 2
n_rep = dat$T_df2..R. + 2
### Partial correlation, so degrees of freedom plus 2 in order to get N
n_orig[dat$ID == 82] <- dat$T_df1..O.[82]+2
n_rep[dat$ID == 82] <- dat$T_df1..R.[82]+2
### Correlation
n_orig[dat$ID == 120] <- dat$T_N..O.[120]
n_rep[dat$ID == 120] <- dat$T_N..R.[120]
n_orig[dat$ID == 154] <- dat$T_N..O.[154]
n_rep[dat$ID == 154] <- dat$T_N..R.[154]
n_orig[dat$ID == 155] <- dat$T_N..O.[155]
n_rep[dat$ID == 155] <- dat$T_N..R.[155]
### t
n_orig[dat$ID == 121] <- dat$T_N..O.[121]
n_rep[dat$ID == 121] <- dat$T_N..R.[121]
### Transform to Fisher's z
fish_orig = atanh(cor_orig)
fish_rep = atanh(cor_rep)
## ----prediction_interval,message=FALSE,warning=FALSE---------------------
se_total <- sqrt(1/(n_orig-3) + 1/(n_rep-3))
low = tanh(fish_orig - se_total * 1.96)
high = tanh(fish_orig + se_total * 1.96)
too_high = (cor_rep > high)
too_low = (cor_rep < low)
use_index = (!is.na(dat$T_pval_USE..O.) & !is.na(dat$T_pval_USE..R.))
pi_dat = data.frame(cor_orig, cor_rep, low, high, se_total, too_low, too_high, n_orig, n_rep,val = (too_low+2*too_high+1),use_index)
pi_dat = dplyr::filter(pi_dat, use_index > 0)
## ----nofilter_plot,message=FALSE,warning=FALSE---------------------------
pi_dat_nona = pi_dat[rowSums(is.na(pi_dat))==0,]
cols1 = c("grey","hotpink","dodgerblue")
plot(pi_dat_nona$cor_orig,pi_dat_nona$cor_rep,ylim=c(-1,1),xlim=c(0,1),
xlab="Original Effect",ylab="Replication Effect",col=cols1[pi_dat_nona$val],pch=19)
abline(c(0,1),lwd=3,lty=2)
abline(h=0,lwd=3,lty=2)
segments(pi_dat_nona$cor_orig,pi_dat_nona$low,pi_dat_nona$cor_orig,pi_dat_nona$high,col=cols1[pi_dat_nona$val],lwd=0.75)
legend(0.55,-0.5,col=c("grey","hotpink","dodgerblue"),pch=19,
legend=c("In prediction interval","Below prediction interval","Above prediction interval"))
## ----make_nofilter_pdf,message=FALSE,warning=FALSE-----------------------
font_import(pattern="Lato",prompt=FALSE)
loadfonts()
pdf(file = "../results/pi_figure_nofilter.pdf",family="Lato")
plot(pi_dat_nona$cor_orig,pi_dat_nona$cor_rep,ylim=c(-1,1),xlim=c(0,1),
xlab="Original Effect",ylab="Replication Effect",bg=cols1[pi_dat_nona$val], col="darkgrey",
pch=21,cex.lab=1.2,cex.axis=1.2,cex=1.2)
abline(c(0,1),lwd=3)
abline(h=0,lwd=3,lty=2)
segments(pi_dat_nona$cor_orig,pi_dat_nona$low,pi_dat_nona$cor_orig,pi_dat_nona$high,col=cols1[pi_dat_nona$val],lwd=0.75)
legend(0.55,-0.5,pt.bg=c("grey","hotpink","dodgerblue"),col="darkgrey",pch=21,
legend=c("In prediction interval","Below prediction interval","Above prediction interval"),cex=1.2)
dev.off()
## ----sample_size_nofilter------------------------------------------------
plot(log10(pi_dat_nona$n_orig),log10(pi_dat_nona$n_rep),
xlab="Original n",ylab="Replication n",col=cols1[pi_dat_nona$val],pch=19,
xaxt="n",yaxt="n")
axis(1,at=log10(c(1,10,100,500,1000,5000,1e5,2.5e5)),
labels = c("1","10","100","500","1000","5000","100,000","250,000"),las=2)
axis(2,at=log10(c(1,10,100,500,1000,5000,1e5,2.5e5)),
labels = c("1","10","100","500","1000","5000","100,000","250,000"),las=2)
abline(c(0,1),lwd=3)
## ----sample_size_nofilter_pdf--------------------------------------------
pdf(file = "../results/samplesize_figure_nofilter.pdf",family="Lato")
plot(log10(pi_dat_nona$n_orig),log10(pi_dat_nona$n_rep),
xlab="Original n",ylab="Replication n",col="darkgrey",bg=cols1[pi_dat_nona$val],pch=21,
xaxt="n",yaxt="n",cex=1.5)
axis(1,at=log10(c(1,10,100,500,1000,5000,1e5,2.5e5)),
labels = c("1","10","100","500","1000","5000","100,000","250,000"),las=2)
axis(2,at=log10(c(1,10,100,500,1000,5000,1e5,2.5e5)),
labels = c("1","10","100","500","1000","5000","100,000","250,000"),las=2)
abline(c(0,1),lwd=3)
dev.off()
## ------------------------------------------------------------------------
table(pi_dat_nona$cor_rep < pi_dat_nona$low)
table(pi_dat_nona$cor_rep < pi_dat_nona$high)
## ------------------------------------------------------------------------
pi_dat = cbind(pi_dat,stat=as.character(fdat$T_Test.Statistic..R.),df1 = fdat$T_df1..O.)
pi_dat = mutate(pi_dat, stat_index= (stat == "F" & df1 == 1) | stat == "t" | stat == "r")
pi_dat_filt = filter(pi_dat,stat_index > 0)
## ----filter_plot,message=FALSE,warning=FALSE-----------------------------
cols1 = c("grey","hotpink","dodgerblue")
plot(pi_dat_filt$cor_orig,pi_dat_filt$cor_rep,ylim=c(-1,1),xlim=c(0,1),
xlab="Original Effect",ylab="Replication Effect",col=cols1[pi_dat_filt$val],pch=19)
abline(c(0,1),lwd=3,lty=2)
abline(h=0,lwd=3,lty=2)
segments(pi_dat_filt$cor_orig,pi_dat_filt$low,pi_dat_filt$cor_orig,pi_dat_filt$high,col=cols1[pi_dat_filt$val],lwd=0.75)
legend(0.55,-0.5,col=c("grey","hotpink","dodgerblue"),pch=19,
legend=c("In prediction interval","Below prediction interval","Above prediction interval"))
## ----make_filter_pdf,message=FALSE,warning=FALSE-------------------------
pdf(file = "../results/pi_figure_filter.pdf",family="Lato")
plot(pi_dat_filt$cor_orig,pi_dat_filt$cor_rep,ylim=c(-1,1),xlim=c(0,1),
xlab="Original Effect",ylab="Replication Effect",bg=cols1[pi_dat_filt$val], col="darkgrey",
pch=21,cex.lab=1.2,cex.axis=1.2,cex=1.2)
abline(c(0,1),lwd=3)
abline(h=0,lwd=3,lty=2)
segments(pi_dat_filt$cor_orig,pi_dat_filt$low,pi_dat_filt$cor_orig,pi_dat_filt$high,col=cols1[pi_dat_filt$val],lwd=1)
legend(0.55,-0.5,pt.bg=c("grey","hotpink","dodgerblue"),col="darkgrey",pch=21,
legend=c("In prediction interval","Below prediction interval","Above prediction interval"),cex=1.2)
dev.off()
plot(log10(pi_dat_filt$n_orig),log10(pi_dat_filt$n_rep),
xlab="Original n",ylab="Replication n",col=cols1[pi_dat_filt$val],pch=19,
xaxt="n",yaxt="n")
axis(1,at=log10(c(1,10,100,500,1000,5000,1e5,2.5e5)),
labels = c("1","10","100","500","1000","5000","100,000","250,000"),las=2)
axis(2,at=log10(c(1,10,100,500,1000,5000,1e5,2.5e5)),
labels = c("1","10","100","500","1000","5000","100,000","250,000"),las=2)
abline(c(0,1),lwd=3)
## ----sample_size_filter_pdf----------------------------------------------
pdf(file = "../results/samplesize_figure_filter.pdf",family="Lato")
plot(log10(pi_dat_filt$n_orig),log10(pi_dat_filt$n_rep),
xlab="Original n",ylab="Replication n",col="darkgrey",bg=cols1[pi_dat_filt$val],pch=21,
xaxt="n",yaxt="n",cex=1.5)
axis(1,at=log10(c(1,10,100,500,1000,5000,1e5,2.5e5)),
labels = c("1","10","100","500","1000","5000","100,000","250,000"),las=2)
axis(2,at=log10(c(1,10,100,500,1000,5000,1e5,2.5e5)),
labels = c("1","10","100","500","1000","5000","100,000","250,000"),las=2)
abline(c(0,1),lwd=3)
legend(log10(9),log10(2000),pt.bg=c("grey","hotpink","dodgerblue"),col="darkgrey",pch=21,
legend=c("In prediction interval","Below prediction interval","Above prediction interval"),cex=1.2)
dev.off()
get_ps <- function(cor_orig, cor_rep, n_orig, n_rep){
# If we don't have a sample size for the replicate, use the sample size
# of the original study. If that is also NA, use the median original sample
# size.
n_rep_tmp <- ifelse(is.na(n_rep), ifelse(is.na(n_orig), 55, n_orig), n_rep)
# If we don't have an original effect size, use the median orignal
# effect size.
cor_orig_tmp <- ifelse(is.na(cor_orig), 0.3501, cor_orig)
mean_term <- 0.5*log((1 + tanh(cor_orig_tmp))/(1 - tanh(cor_orig_tmp)))
# Simulate 100 arcanh(r) assuming the original association is the true
# one, but using the sample size of the replication study to compute the SD
new_arc_rs <- rnorm(100, mean_term, 1/sqrt(n_rep_tmp - 3))
# Convert to R^2
new_r2 <- tanh(new_arc_rs)^2
# Convert to F(1, df2), where df2 is the degrees of freedom from the new study (n_rep_tmp -2)
f_stats <- new_r2/((1/(n_rep_tmp - 2)) - new_r2*(1/(n_rep_tmp - 2)))
# Calculate p-values for all replicates
pf(f_stats, df1=1, df2=(n_rep_tmp-2), lower.tail = FALSE)
}
p.vals <- mapply(get_ps, pi_dat_filt$cor_orig, pi_dat_filt$cor_rep, pi_dat_filt$n_orig, pi_dat_filt$n_rep, SIMPLIFY=TRUE)
p.vals
dim(p.vals)
hist(p.vals[,1])
hist(p.vals[,2])
hist(p.vals[,3])
hist(p.vals[,4])
hist(p.vals[,5])
p_sums <- apply(p.vals, 2, function(x){sum(x < 0.05)})
p_sum
p_sums
length(p_sums)
p_sums <- apply(p.vals, 1, function(x){sum(x < 0.05)})
p_sums
quantile(p_sums)
length(p_sums)
50/73
quantile(p_sums)
quantile(p_sums/73)
hist(p_sums/73)
sales = read.csv("~/Downloads/Sales.csv")
feat = read.csv("~/Downloads/PropFeatures.csv")
sales[1,]
feat[1,]
table(feat$RoomTotalCnt)
table(feat$RoomTotalCnt,useNA="ifany")
table(is.na(feat$RoomTotalCnt))
table(is.na(feat$BathroomCnt))
rm(list=ls())
load("~/Dropbox/Jeff/teaching/2015/advdatasci/fitbit-data.Rdata")
ls()
steps[1,]
plot(steps[,1])
plot(steps[,2])
plot(steps[,3])
plot(steps[,1000])
plot(steps[,500])
plot(steps[,600])
plot(steps[,800])
plot(steps[,900])
plot(steps[,1000])
plot(steps[,950])
plot(steps[,900])
ss = svd(steps - rowMeans(steps))
plot(ss$v[,1])
plot(ss$u[,1])
plot(ss$u[,2])
plot(ss$u[,3])
plot(ss$u[,4])
install.packages("stringr")
install.packages("stringr")
library(stringr)
str_detect(kg$Center,"BCM")[1:40]
suppressPackageStartupMessages({library(dplyr)})
gd_url <- "http://www.stat.ubc.ca/~jenny/notOcto/STAT545A/examples/gapminder/data/gapminderDataFiveYear.txt"
gdf <- read.table(file = gd_url,sep="\t",header=T)
head(gdf)
str(gdf)
gtbl <- tbl_df(gdf)
gtbl
tapply(gtbl$lifeExp,gtbl$continent,mean)
gtbl %>% group_by(continent) %>%
summarize(aveLife = mean(lifeExp))
?substr
tapply(gtbl$lifeExp,gtbl$continent,mean)
sapply(gtbl$contient,function(x){substr(x,1,3)})
tapply(gtbl$lifeExp,gtbl$continent,mean)
sapply(gtbl$continent,function(x){substr(x,1,3)})
?split
split(gtbl$lifeExp,gtbl$continent)
split(gtbl$lifeExp,gtbl$continent)
splitlife= split(gtbl$lifeExp,gtbl$continent)
lapply(splitlife,mean)
